{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import io\n",
    "import torch\n",
    "import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import random\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import auc\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "# import staintools\n",
    "from PIL import ImageOps\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiopsyDataset100(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, df, label, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.df = df\n",
    "        self.image_filenames = []\n",
    "        self.labels = []\n",
    "        self.label = label\n",
    "                \n",
    "        image_dict = {}\n",
    "        for image_filename in glob.glob(os.path.join(self.root_dir, '*.jpeg')):\n",
    "            ID_number = image_filename.split('/')[-1].split('.tif')[0]  # Assuming your filenames are like SCAN1_01.jpg, SCAN1_02.jpg\n",
    "            if ID_number in df.ID_number.tolist():\n",
    "                if ID_number not in image_dict:\n",
    "                    image_dict[ID_number] = []\n",
    "                image_dict[ID_number].append(image_filename)\n",
    "\n",
    "        random.seed(42)\n",
    "        for ID_number, filenames in image_dict.items():\n",
    "            chosen_filenames = random.sample(filenames, min(100, len(filenames)))\n",
    "            for filename in chosen_filenames:\n",
    "                self.image_filenames.append(filename)\n",
    "                self.labels.append(df[df['ID_number'] == ID_number][self.label].values[0])\n",
    "\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = io.imread(self.image_filenames[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    \n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_continous(label, seed):\n",
    "    df = pd.read_excel('data_file.xlsx')\n",
    "    df = df[['ID_number', label]]\n",
    "    df[label] = pd.to_numeric(df[label], errors='coerce')\n",
    "    df = df.dropna(subset=[label])\n",
    "\n",
    "    q20 = df[label].quantile(0.20)\n",
    "    q80 = df[label].quantile(0.80)\n",
    "\n",
    "    # Create new dataframe by filtering values below 20th percentile and above 80th percentile\n",
    "    df_extreme = df[(df[label] <= q20) | (df[label] >= q80)].copy()\n",
    "\n",
    "    # Set labels: 0 for values below or equal to 20th percentile, 1 for values above or equal to 80th percentile\n",
    "    df_extreme.loc[df_extreme[label] <= q20, label] = 0\n",
    "    df_extreme.loc[df_extreme[label] >= q80, label] = 1\n",
    "\n",
    "    \n",
    "    # Now sample the 5 images for each label\n",
    "    np.random.seed(seed)\n",
    "    sampled_df = df_extreme.groupby(label).apply(lambda x: x.sample(n=5)).reset_index(drop=True)\n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c9698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first create an array that contains all the encoded images from the dataset: \n",
    "# And an array for all the labels:\n",
    "\n",
    "def create_encoded_arr(dataset, encoder):\n",
    "    \n",
    "    encoded_arr = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        image = dataset[i][0]\n",
    "        label = dataset[i][1]\n",
    "        \n",
    "        encoded_arr.append(encoder(image))\n",
    "        labels.append(label)\n",
    "\n",
    "    return encoded_arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne(encoded_arr, labels):\n",
    "    flattened_tensors = [tensor.detach().view(-1).numpy() for tensor in encoded_arr]\n",
    "    data_array = np.stack(flattened_tensors)\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "    tsne_results = tsne.fit_transform(data_array)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels, cmap='viridis', alpha=0.7)\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = [plt.cm.viridis(label / max(unique_labels)) for label in unique_labels]\n",
    "    legend_patches = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10, \n",
    "                                 label=f'Label {int(label)}') for label, color in zip(unique_labels, colors)]\n",
    "    plt.legend(handles=legend_patches, title='Labels', bbox_to_anchor=(0.75, 1), loc='upper left')\n",
    "    plt.title('t-SNE Visualization of Encoded Images')\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048092cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = 'Ki67 (%)'\n",
    "# label = 'TILS (%)'\n",
    "# label = 'PR (%)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8919804c",
   "metadata": {},
   "source": [
    "# No encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7909c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(   \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb184c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932903a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = autoencoder.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60504a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430720c",
   "metadata": {},
   "source": [
    "# 16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240de815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_16K(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder_16K, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_16K = Autoencoder_16K()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324dc9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_16K.load_state_dict(torch.load('/storage/Chloe/final_model_autoencoder/autoencoder_64*16*16_split41.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_16K = autoencoder_16K.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41676812",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_16K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa0c0c",
   "metadata": {},
   "source": [
    "# 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_4K(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder_4K, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c12902",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_4K = Autoencoder_4K()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b830dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_4K.load_state_dict(torch.load('/storage/Chloe/final_model_autoencoder/autoencoder_256*4*4_split41.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_4K = autoencoder_4K.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_4K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba028b",
   "metadata": {},
   "source": [
    "# 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a2403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_512(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder_512, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 4, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_512 = Autoencoder_512()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_512.load_state_dict(torch.load('/storage/Chloe/final_model_autoencoder/autoencoder_128*2*2_split41.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9043a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_512 = autoencoder_512.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afdbfb6",
   "metadata": {},
   "source": [
    "# 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ea7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_64(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder_64, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 4, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_64 = Autoencoder_64()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_64.load_state_dict(torch.load('/storage/Chloe/final_model_autoencoder/autoencoder_64*1*1_split41.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_64 = autoencoder_64.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf4b85",
   "metadata": {},
   "source": [
    "# 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679682fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder_2, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2, 4, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdaaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_2 = Autoencoder_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d529dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_2.load_state_dict(torch.load('/storage/Chloe/final_model_autoencoder/autoencoder_2*1*1_split41.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_2 = autoencoder_2.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c92556",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbccadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Ki67 (%)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e7ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No autoencoder\n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13461743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 16K \n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_16K)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519e9c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4K \n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_4K)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae0998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 512 \n",
    "for i in range(10): \n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_512)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5c434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 64\n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_64)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce7304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2 \n",
    "for i in range(10):\n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_2)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d0c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label =  'TILS (%)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8afbc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No autoencoder\n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed4ea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 16K \n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_16K)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a12203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4K \n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_4K)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3668a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 512 \n",
    "for i in range(10): \n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_512)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fd2ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 64\n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_64)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9177614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2 \n",
    "for i in range(10):\n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_2)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39b2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad303ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'PR (%)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191cae6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No autoencoder\n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81fe1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 16K \n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_16K)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66650559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4K \n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_4K)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee9cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 512 \n",
    "for i in range(10): \n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_512)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3400857b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 64\n",
    "for i in range(10): \n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_64)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2697487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2 \n",
    "for i in range(10):\n",
    "    print(f\"Seed : {i}\")\n",
    "    sampled_df = get_dataset_continous(label, i)\n",
    "    dataset = BiopsyDataset100(\"/storage/Chloe/zoom_20_512\", sampled_df, label, transform=transform)\n",
    "    encoded_arr, labels = create_encoded_arr(dataset, encoder_2)\n",
    "    print(encoded_arr[0].shape)\n",
    "    tsne(encoded_arr, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c71ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c752b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c77e3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a8dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb1bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102a704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('asaf_37': conda)",
   "language": "python",
   "name": "python37364bitasaf37condaa6fb81c804d44916ac4c145cffbdf473"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
