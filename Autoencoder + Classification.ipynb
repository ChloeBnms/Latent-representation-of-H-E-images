{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18369fda",
   "metadata": {},
   "source": [
    "# Autoencoder + Classification on encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import io\n",
    "import torch\n",
    "import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import auc\n",
    "import copy\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "# import staintools\n",
    "from PIL import ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eee0a1",
   "metadata": {},
   "source": [
    "## Prepare the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedbfc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Ki67 (%)'\n",
    "df = pd.read_excel('data_file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ID_number', label]]\n",
    "df = df.dropna(subset=[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df[label], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q20 = df[label].quantile(0.20)\n",
    "q80 = df[label].quantile(0.80)\n",
    "print(q20)\n",
    "print(q80)\n",
    "\n",
    "# Create new dataframe by filtering values below 20th percentile and above 80th percentile\n",
    "df_extreme = df[(df[label] <= q20) | (df[label] >= q80)].copy()\n",
    "\n",
    "# Set labels: 0 for values below or equal to 20th percentile, 1 for values above or equal to 80th percentile\n",
    "df_extreme.loc[df_extreme[label] <= q20, label] = 0\n",
    "df_extreme.loc[df_extreme[label] >= q80, label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q20 = df[label].quantile(0.20)\n",
    "q80 = df[label].quantile(0.80)\n",
    "q30 = df[label].quantile(0.30)\n",
    "q70 = df[label].quantile(0.70)\n",
    "\n",
    "# Create new dataframe by filtering values between 20th and 30th percentile and between 70th and 80th percentile\n",
    "df_ood = df[((df[label] <= q30) & (df[label] > q20)) | ((df[label] < q80) & (df[label] >= q70))].copy()\n",
    "df_ood.loc[df_ood[label] <= q30, label] = 0\n",
    "df_ood.loc[df_ood[label] >= q70, label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ac54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_extreme[label], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c3a19",
   "metadata": {},
   "source": [
    "# Create the different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10e198",
   "metadata": {},
   "source": [
    "## Create the original dataset with all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiopsyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, df, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.df = df\n",
    "        self.image_filenames = []\n",
    "        self.labels = []\n",
    "\n",
    "        for image_filename in glob.glob(os.path.join(self.root_dir, '*.jpeg')):\n",
    "            ID_number = image_filename.split('/')[-1].split('.tif')[0]\n",
    "            if ID_number in df.ID_number.tolist():\n",
    "                self.image_filenames.append(image_filename)\n",
    "                self.labels.append(df[df['ID_number'] == ID_number][label].values[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = io.imread(self.image_filenames[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    \n",
    "    def get_label_indices(self):\n",
    "        # Get indices for labels 0 and 1\n",
    "        zeros_indices = [i for i, x in enumerate(self.labels) if x == 0]\n",
    "        ones_indices = [i for i, x in enumerate(self.labels) if x == 1]\n",
    "        return zeros_indices, ones_indices\n",
    "    \n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# Create train, validation and test sets\n",
    "train_df, temp_df = train_test_split(df_extreme, test_size=0.3, random_state=41, stratify=df_extreme[label])\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.33, random_state=41, stratify=temp_df[label])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BiopsyDataset(\"/storage/Chloe/zoom_20_512\", train_df, transform=transform)\n",
    "valid_dataset = BiopsyDataset(\"/storage/Chloe/zoom_20_512\", valid_df, transform=transform)\n",
    "test_dataset = BiopsyDataset(\"/storage/Chloe/zoom_20_512\", test_df, transform=transform)\n",
    "test_dataset_ood = BiopsyDataset(\"/storage/Chloe/zoom_20_512\", df_ood, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda74a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(test_dataset_ood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a55608",
   "metadata": {},
   "source": [
    "## Create balanced datasets with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset_indices, original_dataset):\n",
    "        self.subset_indices = subset_indices\n",
    "        self.original_dataset = original_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        original_index = self.subset_indices[index]\n",
    "        return self.original_dataset[original_index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_data(dataset):\n",
    "    zero_index, one_index = dataset.get_label_indices()\n",
    "    min_class_size = min(len(zero_index), len(one_index))\n",
    "    np.random.seed(42) # Set the random seed for reproducibility\n",
    "    balanced_indices_class0 = np.random.choice(zero_index, size=min_class_size, replace=False)\n",
    "    balanced_indices_class1 = np.random.choice(one_index, size=min_class_size, replace=False)\n",
    "    balanced_indices = np.concatenate([balanced_indices_class0, balanced_indices_class1])\n",
    "    balanced_dataset = SubsetDataset(balanced_indices, dataset)\n",
    "    return balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train_dataset = balanced_data(train_dataset)\n",
    "balanced_valid_dataset = balanced_data(valid_dataset)\n",
    "balanced_test_dataset = balanced_data(test_dataset)\n",
    "balanced_test_ood_dataset = balanced_data(test_dataset_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60530f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(balanced_train_dataset))\n",
    "print(len(balanced_valid_dataset))\n",
    "print(len(balanced_test_dataset))\n",
    "print(len(balanced_test_ood_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c4110",
   "metadata": {},
   "source": [
    "## Create unlabeled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, labeled_dataset):\n",
    "        self.labeled_dataset = labeled_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, _ = self.labeled_dataset[idx]  # Ignore label\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unlabeled_dataset = UnlabeledDataset(balanced_train_dataset)\n",
    "train_unlabeled_dataloader = DataLoader(train_unlabeled_dataset, batch_size=16, shuffle=True)\n",
    "valid_unlabeled_dataset = UnlabeledDataset(balanced_valid_dataset)\n",
    "valid_unlabeled_dataloader = DataLoader(valid_unlabeled_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fb6baf",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are all the autoencoders needed, \n",
    "# Comment all except the one in the latent dimension you want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86973010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent dimension 16,496\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [16, 64, 16, 16]\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent dimension 4096:\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),            \n",
    "\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [16, 256, 4, 4]\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f49a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent dimension 512\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),      \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), \n",
    "\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 4, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [16, 128, 2, 2]\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent dimension 64\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),      \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1), \n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 4, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [16, 64, 1, 1]\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent dimension 2\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=2, padding=1),      \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, kernel_size=3, stride=2, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, kernel_size=3, stride=2, padding=1), \n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2, 4, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [16, 2, 1, 1]\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff1656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, trainloader, validloader, device, criterion, optimizer, num_epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(trainloader):.4f}\")\n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(validloader, 0):\n",
    "                inputs = data.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "        val_loss = running_val_loss / len(validloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # If this model is better, update best_val_loss and best_model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            print(f\"Best validation loss improved to {best_val_loss:.4f}. Saving model...\")\n",
    "\n",
    "        # Plotting original and reconstructed images after each epoch on validation set\n",
    "        with torch.no_grad():\n",
    "            inputs = next(iter(validloader)).to(device)\n",
    "            outputs = model(inputs)\n",
    "            n = min(inputs.size(0), 5)\n",
    "            comparison = torch.cat([inputs[:n], outputs.view(-1, 3, 128, 128)[:n]])\n",
    "            img_grid = torchvision.utils.make_grid(comparison.cpu().detach(), nrow=n)\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.imshow(np.transpose(img_grid, (1, 2, 0)))\n",
    "            plt.title('Original and Reconstructed Images')\n",
    "            plt.show()\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    return best_model\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "best_model = train(model, train_unlabeled_dataloader, valid_unlabeled_dataloader, device, criterion, optimizer, num_epochs=40)\n",
    "torch.save(best_model, '/storage/Chloe/final_model_autoencoder/autoencoder_64*16*16_split41_check.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba3e1f6",
   "metadata": {},
   "source": [
    "# Load autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d499f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "autoencoder = Autoencoder().to(device)\n",
    "autoencoder.load_state_dict(torch.load('/storage/Chloe/final_model_autoencoder/autoencoder_64*16*16_split41_check.pth'))\n",
    "encoder = autoencoder.encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b397612",
   "metadata": {},
   "source": [
    "# Create transformed encoded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d00e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, base_dataset, transform):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.base_dataset[idx]\n",
    "        return self.transform(image), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c98b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train_dataset = TransformedDataset(balanced_train_dataset, transform)\n",
    "transformed_valid_dataset = TransformedDataset(balanced_valid_dataset, transform)\n",
    "transformed_test_dataset = TransformedDataset(balanced_test_dataset, transform)\n",
    "transformed_test_ood_dataset = TransformedDataset(balanced_test_ood_dataset, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd739bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, original_dataset, encoder):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_image, label = self.original_dataset[idx]\n",
    "        original_image = original_image.to(next(self.encoder.parameters()).device)\n",
    "        encoded_image = self.encoder(original_image.unsqueeze(0)).squeeze(0).detach()\n",
    "        return encoded_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_dataset = EncodedDataset(transformed_train_dataset, encoder)\n",
    "encoded_valid_dataset = EncodedDataset(transformed_valid_dataset, encoder)\n",
    "encoded_test_dataset = EncodedDataset(transformed_test_dataset, encoder)\n",
    "encoded_test_ood_dataset = EncodedDataset(transformed_test_ood_dataset, encoder)\n",
    "encoded_test_ood_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_dataloader_cl = DataLoader(encoded_train_dataset, batch_size=8, shuffle=True)\n",
    "valid_dataloader_cl = DataLoader(encoded_valid_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader_cl = DataLoader(encoded_test_dataset, batch_size=8, shuffle=True)\n",
    "test_ood_dataloader_cl = DataLoader(encoded_test_ood_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c765ad0",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  \n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs).view(-1)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "        true_labels.extend(labels.int().tolist())\n",
    "        predictions.extend(preds.tolist())\n",
    "        prediction_probs.extend(torch.sigmoid(outputs).tolist())\n",
    "    \n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    auc = roc_auc_score(true_labels, prediction_probs)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    print(f\"AUC-ROC Score: {auc}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, valid_dataloader, criterion, optimizer, num_epochs, filename):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).view(-1)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "        epoch_acc = running_corrects / len(train_dataloader.dataset)\n",
    "        valid_acc = evaluate_model(model, valid_dataloader)\n",
    "\n",
    "        if valid_acc > best_acc:\n",
    "            best_epoch = epoch\n",
    "            best_acc = valid_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), filename)\n",
    "\n",
    "        print(f'Epoch {epoch}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc}, Valid Acc: {valid_acc}')\n",
    "\n",
    "    print(f'Best epoch at {best_epoch}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179425be",
   "metadata": {},
   "source": [
    "## Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b653708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelResnet(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(MyModelResnet, self).__init__()\n",
    "        self.conv = nn.Conv2d(64, 3, kernel_size=1)\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.base_model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# model_base = models.resnet50(pretrained=True)\n",
    "model_base = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "# Modify the final layer of the base models\n",
    "num_ftrs = model_base.fc.in_features\n",
    "model_base.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "model = MyModelResnet(model_base)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer1 = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65662961",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = train_model(\n",
    "    model, \n",
    "    train_dataloader_cl, \n",
    "    valid_dataloader_cl, \n",
    "    criterion, optimizer1, \n",
    "    num_epochs=20, \n",
    "    filename='/storage/Chloe/final_models_classification/split41_check_64*16*16_Resnet.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91145e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate_model(best_classifier, test_dataloader_cl)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a948962",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_test_acc = evaluate_model(best_classifier, test_ood_dataloader_cl)\n",
    "print(f'Test accuracy on ood: {ood_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605bed3",
   "metadata": {},
   "source": [
    "## Densenet 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37212058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelDensenet(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(MyModelDensenet, self).__init__()\n",
    "        self.conv = nn.Conv2d(64, 3, kernel_size=1)\n",
    "        self.upsample = nn.Upsample((32, 32))\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.upsample(x)\n",
    "        x = self.base_model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_base = models.densenet121(pretrained=True)\n",
    "num_ftrs = model_base.classifier.in_features\n",
    "model_base.classifier = nn.Linear(num_ftrs, 1)\n",
    "model = MyModelDensenet(model_base)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer1 = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = train_model(model, train_dataloader_cl, valid_dataloader_cl, criterion, optimizer1, num_epochs=20, filename='/storage/Chloe/final_models_classification/split41_check_64*16*16_Densenet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate_model(best_classifier, test_dataloader_cl)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_test_acc = evaluate_model(best_classifier, test_ood_dataloader_cl)\n",
    "print(f'Test accuracy on ood: {ood_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61443809",
   "metadata": {},
   "source": [
    "## Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelInceptionV3(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(MyModelInceptionV3, self).__init__()\n",
    "        self.conv = nn.Conv2d(64, 3, kernel_size=1)\n",
    "        self.upsample = nn.Upsample((299, 299))\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.upsample(x)\n",
    "        if self.training and self.base_model.aux_logits:\n",
    "            x, _ = self.base_model(x)\n",
    "        else:\n",
    "            x = self.base_model(x)\n",
    "        return x\n",
    "\n",
    "model_base = models.inception_v3(pretrained=True, aux_logits=True)\n",
    "\n",
    "# Inception v3 has two final layers (one main and one auxiliary). \n",
    "# We need to change both of them to match our binary classification task\n",
    "num_ftrs = model_base.fc.in_features\n",
    "model_base.fc = nn.Linear(num_ftrs, 1)\n",
    "num_aux_ftrs = model_base.AuxLogits.fc.in_features\n",
    "model_base.AuxLogits.fc = nn.Linear(num_aux_ftrs, 1)\n",
    "model = MyModelInceptionV3(model_base)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer1 = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = train_model(\n",
    "    model, \n",
    "    train_dataloader_cl, \n",
    "    valid_dataloader_cl, \n",
    "    criterion, \n",
    "    optimizer1, \n",
    "    num_epochs=20, \n",
    "    filename='/storage/Chloe/final_models_classification/split41_check_64*16*16_Inception.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate_model(best_classifier, test_dataloader_cl)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_test_acc = evaluate_model(best_classifier, test_ood_dataloader_cl)\n",
    "print(f'Test accuracy on ood: {ood_test_acc}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('asaf_37': conda)",
   "language": "python",
   "name": "python37364bitasaf37condaa6fb81c804d44916ac4c145cffbdf473"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
