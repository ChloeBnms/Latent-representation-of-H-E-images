{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273461c9",
   "metadata": {},
   "source": [
    "# Direct classification from tile to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e6c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import io\n",
    "import torch\n",
    "import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import auc\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "# import staintools\n",
    "from PIL import ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc361dd",
   "metadata": {},
   "source": [
    "## Prepare the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "43756633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data_file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a2b949a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all the labels: \n",
    "# Comment all except the one you want to analyze \n",
    "\n",
    "# Numerical Labels: \n",
    "label = \"Ki67 (%)\"\n",
    "label = \"TILS (%)\"\n",
    "label = \"PR (%)\"\n",
    "label = \"MYC\"\n",
    "label = \"FOXA1\"\n",
    "label = \"HIF1A\"\n",
    "label = \"ROR.S..Subtype.Only.\"\n",
    "label = \"ROR.P..Subtype...Proliferation.\"\n",
    "\n",
    "# Binary Labels: \n",
    "label = \"PR status\" # Positive / Negative\n",
    "label = \"PAM50 subtype\" # Luminal A / Luminal B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "00e878fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_number</th>\n",
       "      <th>PAM50 subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCAN_0054</td>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCAN_0055</td>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCAN_0056</td>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCAN_0057</td>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCAN_0058</td>\n",
       "      <td>LumB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>SCAN_0240</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>SCAN_0241</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>SCAN_0469</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>SCAN_0470</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>SCAN_0471</td>\n",
       "      <td>LumA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID_number PAM50 subtype\n",
       "0    SCAN_0054          LumB\n",
       "1    SCAN_0055          LumB\n",
       "2    SCAN_0056          LumB\n",
       "3    SCAN_0057          LumB\n",
       "4    SCAN_0058          LumB\n",
       "..         ...           ...\n",
       "276  SCAN_0240          LumA\n",
       "277  SCAN_0241          LumA\n",
       "278  SCAN_0469          LumA\n",
       "279  SCAN_0470          LumA\n",
       "280  SCAN_0471          LumA\n",
       "\n",
       "[280 rows x 2 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['ID_number', label]]\n",
    "df = df.dropna(subset=[label])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b8a1e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[label].notna()]\n",
    "\n",
    "if label == \"PAM50 subtype\":\n",
    "    df = df[df[label].isin(['LumA', 'LumB'])]\n",
    "    df[label] = df[label].replace({'LumA': 0, 'LumB': 1})\n",
    "    \n",
    "elif label == \"PR status\":\n",
    "    df[label] = df[label].replace({'Negative': 0, 'Positive': 1})\n",
    "\n",
    "# else label is numerical\n",
    "else:\n",
    "    df[label] = pd.to_numeric(df[label], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f6e41125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([141, 135]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df[label], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5acc7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "q20 = df[label].quantile(0.20)\n",
    "q80 = df[label].quantile(0.80)\n",
    "\n",
    "# Create new dataframe by filtering values below 20th percentile and above 80th percentile\n",
    "df_extreme = df[(df[label] <= q20) | (df[label] >= q80)].copy()\n",
    "\n",
    "# Set labels: 0 for values below or equal to 20th percentile, 1 for values above or equal to 80th percentile\n",
    "df_extreme.loc[df_extreme[label] <= q20, label] = -100\n",
    "df_extreme.loc[df_extreme[label] >= q80, label] = 100\n",
    "\n",
    "df_extreme.replace({-100: 0, 100: 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "afe7a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create out of distribution set for numerical values:\n",
    "if label != \"PR status\" and label != \"PAM50 subtype\":\n",
    "    q20 = df[label].quantile(0.20)\n",
    "    q80 = df[label].quantile(0.80)\n",
    "    q30 = df[label].quantile(0.30)\n",
    "    q70 = df[label].quantile(0.70)\n",
    "\n",
    "    # Create new dataframe by filtering values between 20th and 30th percentile and between 70th and 80th percentile\n",
    "    df_ood = df[((df[label] <= q30) & (df[label] > q20)) | ((df[label] < q80) & (df[label] >= q70))].copy()\n",
    "    df_ood.loc[df_ood[label] <= q30, label] = -100\n",
    "    df_ood.loc[df_ood[label] >= q70, label] = 100\n",
    "    df_ood.replace({-100: 0, 100: 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97bc95",
   "metadata": {},
   "source": [
    "# Create the different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f71bf",
   "metadata": {},
   "source": [
    "## Create the original dataset with all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d55c3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiopsyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, df, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.df = df\n",
    "        self.image_filenames = []\n",
    "        self.labels = []\n",
    "\n",
    "        for image_filename in glob.glob(os.path.join(self.root_dir, '*.jpeg')):\n",
    "            ID_number = image_filename.split('/')[-1].split('.tif')[0]\n",
    "            if ID_number in df.ID_number.tolist():\n",
    "                self.image_filenames.append(image_filename)\n",
    "                self.labels.append(df[df['ID_number'] == ID_number][label].values[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = io.imread(self.image_filenames[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    \n",
    "    def get_label_indices(self):\n",
    "        # Get indices for labels 0 and 1\n",
    "        zeros_indices = [i for i, x in enumerate(self.labels) if x == 0]\n",
    "        ones_indices = [i for i, x in enumerate(self.labels) if x == 1]\n",
    "        return zeros_indices, ones_indices\n",
    "    \n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create train, validation and test sets\n",
    "train_df, temp_df = train_test_split(df_extreme, test_size=0.3, random_state=41, stratify=df_extreme[label])\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.33, random_state=41, stratify=temp_df[label])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BiopsyDataset(\"/storage/Chloe/zoom_20_512\", train_df, transform=transform)\n",
    "valid_dataset = BiopsyDataset(\"/storage/Chloe/zoom_20_512\", valid_df, transform=transform)\n",
    "test_dataset = BiopsyDataset(\"/storage/Chloe/zoom_20_512\", test_df, transform=transform)\n",
    "if label != \"PR status\" and label != \"PAM50 subtype\":\n",
    "    test_dataset_ood = BiopsyDataset(\"/storage/Chloe/zoom_20_512\", df_ood, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c7ee5806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158810\n",
      "48608\n",
      "29295\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(len(test_dataset))\n",
    "if label != \"PR status\" and label != \"PAM50 subtype\":\n",
    "    print(len(test_dataset_ood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d90c45",
   "metadata": {},
   "source": [
    "## Create balanced datasets with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "080580b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset_indices, original_dataset):\n",
    "        self.subset_indices = subset_indices\n",
    "        self.original_dataset = original_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        original_index = self.subset_indices[index]\n",
    "        return self.original_dataset[original_index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d71d1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_data(dataset):\n",
    "    zero_index, one_index = dataset.get_label_indices()\n",
    "    min_class_size = min(len(zero_index), len(one_index))\n",
    "    np.random.seed(42)  # Set the random seed for reproducibility\n",
    "    balanced_indices_class0 = np.random.choice(zero_index, size=min_class_size, replace=False)\n",
    "    balanced_indices_class1 = np.random.choice(one_index, size=min_class_size, replace=False)\n",
    "    balanced_indices = np.concatenate([balanced_indices_class0, balanced_indices_class1])\n",
    "    balanced_dataset = SubsetDataset(balanced_indices, dataset)\n",
    "    return balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ca408137",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train_dataset = balanced_data(train_dataset)\n",
    "balanced_valid_dataset = balanced_data(valid_dataset)\n",
    "balanced_test_dataset = balanced_data(test_dataset)\n",
    "if label != \"PR status\" and label != \"PAM50 subtype\":\n",
    "    balanced_test_ood_dataset = balanced_data(test_dataset_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d9c0bc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89058\n",
      "18788\n",
      "20722\n"
     ]
    }
   ],
   "source": [
    "print(len(balanced_train_dataset))\n",
    "print(len(balanced_valid_dataset))\n",
    "print(len(balanced_test_dataset))\n",
    "if label != \"PR status\" and label != \"PAM50 subtype\":\n",
    "    print(len(balanced_test_ood_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c6e18f",
   "metadata": {},
   "source": [
    "## Create transformed dataset with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4bc6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, base_dataset, transform):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.base_dataset[idx]\n",
    "        return self.transform(image), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6303df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dfc939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train_dataset = TransformedDataset(balanced_train_dataset, transform)\n",
    "transformed_valid_dataset = TransformedDataset(balanced_valid_dataset, transform)\n",
    "transformed_test_dataset = TransformedDataset(balanced_test_dataset, transform)\n",
    "if label != \"PR status\" and label != \"PAM50 subtype\":\n",
    "    transformed_test_ood_dataset = TransformedDataset(balanced_test_ood_dataset, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9705a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(transformed_train_dataset, batch_size=8, shuffle=True)\n",
    "valid_dataloader = DataLoader(transformed_valid_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(transformed_test_dataset, batch_size=8, shuffle=True)\n",
    "if label != \"PR status\" and label != \"PAM50 subtype\":\n",
    "    test_ood_dataloader = DataLoader(transformed_test_ood_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62cccf2",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a42584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  \n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs).view(-1)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "        true_labels.extend(labels.int().tolist())\n",
    "        predictions.extend(preds.tolist())\n",
    "        prediction_probs.extend(torch.sigmoid(outputs).tolist())\n",
    "    \n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    auc = roc_auc_score(true_labels, prediction_probs)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    print(f\"AUC-ROC Score: {auc}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e33817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, valid_dataloader, criterion, optimizer, num_epochs, file_path):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).view(-1)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "        epoch_acc = running_corrects / len(train_dataloader.dataset)\n",
    "        valid_acc = evaluate_model(model, valid_dataloader)\n",
    "\n",
    "        if valid_acc > best_acc:\n",
    "            best_epoch = epoch\n",
    "            best_acc = valid_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), file_path)\n",
    "\n",
    "        print(f'Epoch {epoch}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc}, Valid Acc: {valid_acc}')\n",
    "\n",
    "    print(f'Best epoch at {best_epoch}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82612d8",
   "metadata": {},
   "source": [
    "## Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dba5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelResnet(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(MyModelResnet, self).__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        return x\n",
    "\n",
    "model_base = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final layer of the base models\n",
    "num_ftrs = model_base.fc.in_features\n",
    "model_base.fc = nn.Linear(num_ftrs, 1)\n",
    "model = MyModelResnet(model_base)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer1 = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44871d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = train_model(\n",
    "    model, \n",
    "    train_dataloader, \n",
    "    valid_dataloader, \n",
    "    criterion, \n",
    "    optimizer1, \n",
    "    num_epochs=20, \n",
    "    file_path = '/storage/Chloe/final_models_classification/direct_classification_Ki67_2_Resnet_split41.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79648319",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate_model(best_classifier, test_dataloader)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ccc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if label != \"PR status\" and label != \"PAM50 subtype\":\n",
    "    test_ood_acc = evaluate_model(best_classifier, test_ood_dataloader)\n",
    "    print(f'Test ood accuracy: {test_ood_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730050cc",
   "metadata": {},
   "source": [
    "## Densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18648f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelDensenet(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(MyModelDensenet, self).__init__()\n",
    "        self.upsample = nn.Upsample((32, 32))\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.base_model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_base = models.densenet121(pretrained=True)\n",
    "num_ftrs = model_base.classifier.in_features\n",
    "model_base.classifier = nn.Linear(num_ftrs, 1)\n",
    "model = MyModelDensenet(model_base)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer1 = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = train_model(\n",
    "    model, \n",
    "    train_dataloader, \n",
    "    valid_dataloader, \n",
    "    criterion, \n",
    "    optimizer1, \n",
    "    num_epochs=20, \n",
    "    file_path='/storage/Chloe/final_models_classification/direct_classification_Ki67_2_densenet_split41.pth'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate_model(best_classifier, test_dataloader)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6cc1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if label != \"PR status\" and label != \"PAM50 subtype\":\n",
    "    test_ood_acc = evaluate_model(best_classifier, test_ood_dataloader)\n",
    "    print(f'Test ood accuracy: {test_ood_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d4a1c3",
   "metadata": {},
   "source": [
    "## Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelInceptionV3(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(MyModelInceptionV3, self).__init__()\n",
    "        self.upsample = nn.Upsample((299, 299))\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        if self.training and self.base_model.aux_logits:\n",
    "            x, _ = self.base_model(x)\n",
    "        else:\n",
    "            x = self.base_model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model_base = models.inception_v3(pretrained=True, aux_logits=True)\n",
    "num_ftrs = model_base.fc.in_features\n",
    "model_base.fc = nn.Linear(num_ftrs, 1)\n",
    "num_aux_ftrs = model_base.AuxLogits.fc.in_features\n",
    "model_base.AuxLogits.fc = nn.Linear(num_aux_ftrs, 1)\n",
    "model = MyModelInceptionV3(model_base)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer1 = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = train_model(\n",
    "    model, \n",
    "    train_dataloader, \n",
    "    valid_dataloader, \n",
    "    criterion, \n",
    "    optimizer1, \n",
    "    num_epochs=20, \n",
    "    file_path='/storage/Chloe/final_models_classification/direct_classification_Ki67_2_Inception_split41.pth'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate_model(best_classifier, test_dataloader)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if label != \"PR status\" and label != \"PAM50 subtype\":\n",
    "    test_ood_acc = evaluate_model(best_classifier, test_ood_dataloader)\n",
    "    print(f'Test ood accuracy: {test_ood_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb4193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('asaf_37': conda)",
   "language": "python",
   "name": "python37364bitasaf37condaa6fb81c804d44916ac4c145cffbdf473"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
